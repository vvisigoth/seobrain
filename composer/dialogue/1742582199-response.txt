```python
def parser_add_argument(parser):
    """Add model and provider arguments to the parser"""
    parser.add_argument("-o", "--output", default=DEFAULT_ARTICLE_COUNT, 
                        help=f"Output directory (default: {OUTPUT_DIR})")
    parser.add_argument("-m", "--model", default=DEFAULT_MODEL, 
                        help=f"AI model to use (default: {DEFAULT_MODEL})")
    parser.add_argument("-p", "--provider", default=DEFAULT_PROVIDER, 
                        choices=["ollama", "openai", "openrouter", "anthropic"],
                        help=f"AI provider (default: {DEFAULT_PROVIDER})")
    parser.add_argument("-s", "--server", default=SERVER_URL, 
                        help=f"Server URL (default: {SERVER_URL})")
    parser.add_argument("-n", "--num-articles", type=int, default=DEFAULT_ARTICLE_COUNT,
                        help=f"Number of articles to generate (default: {DEFAULT_ARTICLE_COUNT})")
```

Here's the completed implementation of the enhanced outliner.py script:

```python
#!python3.12
"""
SEO Generation Script

This script takes a text file where each line is an SEO keyword
and generates optimized content that covers multiple keywords in each article.
"""

import os
import sys
import argparse
import json
import requests
import random
from pathlib import Path
from typing import List, Dict, Any, Optional

# Default settings
DEFAULT_MODEL = "anthropic/claude-3.7-sonnet"
DEFAULT_PROVIDER = "openrouter"
SERVER_URL = "http://localhost:5555"
OUTPUT_DIR = "seo_content"
DEFAULT_ARTICLE_COUNT = 50

def load_keywords(file_path: str) -> List[str]:
    """Load keywords from a text file, one per line."""
    with open(file_path, 'r') as f:
        return [line.strip() for line in f if line.strip()]

def distribute_keywords(keywords: List[str], article_count: int) -> List[List[str]]:
    """
    Distribute all keywords across the specified number of articles.
    Each article will include multiple keywords.
    """
    # Ensure we don't create more articles than keywords
    article_count = min(article_count, len(keywords))
    
    # Shuffle keywords to randomize distribution
    shuffled_keywords = keywords.copy()
    random.shuffle(shuffled_keywords)
    
    # Calculate minimum keywords per article
    min_keywords_per_article = len(shuffled_keywords) // article_count
    remaining = len(shuffled_keywords) % article_count
    
    # Distribute keywords to articles
    articles = []
    index = 0
    for i in range(article_count):
        # Add one extra keyword to some articles if there are remainders
        count = min_keywords_per_article + (1 if i < remaining else 0)
        article_keywords = shuffled_keywords[index:index + count]
        articles.append(article_keywords)
        index += count
    
    return articles

def generate_seo_content(keywords: List[str], model: str, provider: str, server_url: str) -> str:
    """Generate SEO content for a given set of keywords using the AI API."""
    
    # Format the keywords for the prompt
    keywords_str = ", ".join([f'"{kw}"' for kw in keywords])
    primary_keyword = keywords[0]  # Use the first keyword as primary
    
    # Craft the prompt for SEO content generation
    prompt = f"""
Generate high-quality SEO content that incorporates ALL of the following keywords: {keywords_str}

Use "{primary_keyword}" as the primary focus, but naturally integrate all the other keywords throughout the article.

Please include:
1. A compelling H1 title (using markdown # syntax) that includes the primary keyword
2. A meta description (150-160 characters) that mentions 2-3 of the keywords
3. 5-7 relevant H2 subheadings (using markdown ## syntax) that incorporate different keywords
4. 800-1200 words of well-structured, informative content that naturally includes all keywords
5. A natural keyword density without keyword stuffing
6. A clear call-to-action at the end

The content should be engaging, informative, and optimized for search engines while providing genuine value to readers.
Ensure the article flows naturally and doesn't feel like it's artificially cramming in keywords.
"""

    # Prepare request data
    request_data = {
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 4000,
        "temperature": 0.7,
        "provider": provider,
        "model": model
    }

    # Send request to server
    try:
        response = requests.post(
            f"{server_url}/api/generate",
            json=request_data,
            headers={"Content-Type": "application/json"}
        )

        if response.status_code != 200:
            raise Exception(f"HTTP error: {response.status_code} - {response.text}")

        return response.json()["content"]
    
    except requests.exceptions.RequestException as e:
        raise Exception(f"Connection error: {str(e)}")

def save_content(primary_keyword: str, all_keywords: List[str], content: str, output_dir: str) -> str:
    """Save the generated content to a file and return the file path."""
    # Create output directory if it doesn't exist
    Path(output_dir).mkdir(exist_ok=True)
    
    # Create a filename from the primary keyword
    filename = primary_keyword.lower().replace(' ', '_').replace("'", "").replace('"', '')
    # Remove any special characters that might cause issues with filenames
    filename = ''.join(c for c in filename if c.isalnum() or c == '_' or c == '-')
    filepath = os.path.join(output_dir, f"{filename}.md")
    
    # Add a header comment with all keywords used
    keywords_comment = "<!--\nKeywords covered in this article